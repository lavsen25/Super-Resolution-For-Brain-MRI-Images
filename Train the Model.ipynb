{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, Activation, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "import os\n",
    "patch_size =64\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tf_fspecial_gauss(size, sigma):\n",
    "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
    "    \"\"\"\n",
    "    x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "    x_data = np.expand_dims(x_data, axis=-1)\n",
    "\n",
    "    y_data = np.expand_dims(y_data, axis=-1)\n",
    "    y_data = np.expand_dims(y_data, axis=-1)\n",
    "\n",
    "    x = tf.constant(x_data, dtype=tf.float32)\n",
    "    y = tf.constant(y_data, dtype=tf.float32)\n",
    "\n",
    "    g = tf.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
    "    return g / tf.reduce_sum(g)\n",
    "\n",
    "\n",
    "def ssim (y_true, y_pred):\n",
    "    return tf_ssim(y_true, y_pred, cs_map=False, mean_metric=True, size=11, sigma=1.5)\n",
    "def tf_ssim(img1, img2, cs_map=False, mean_metric=True, size=11, sigma=1.5):\n",
    "    img1 = tf.reshape(img1, [1, 64, -1, 1])\n",
    "    img2 = tf.reshape(img2, [1, 64, -1, 1]) \n",
    "    \n",
    "    window = _tf_fspecial_gauss(size, sigma) # window shape [size, size]\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    L = 1  # depth of image (255 in case the image has a differnt scale)\n",
    "    C1 = (K1*L)**2\n",
    "    C2 = (K2*L)**2\n",
    "    mu1 = tf.nn.conv2d(img1, window, strides=[1,1,1,1], padding='VALID')\n",
    "    mu2 = tf.nn.conv2d(img2, window, strides=[1,1,1,1],padding='VALID')\n",
    "    mu1_sq = mu1*mu1\n",
    "    mu2_sq = mu2*mu2\n",
    "    mu1_mu2 = mu1*mu2\n",
    "    sigma1_sq = tf.nn.conv2d(img1*img1, window, strides=[1,1,1,1],padding='VALID') - mu1_sq\n",
    "    sigma2_sq = tf.nn.conv2d(img2*img2, window, strides=[1,1,1,1],padding='VALID') - mu2_sq\n",
    "    sigma12 = tf.nn.conv2d(img1*img2, window, strides=[1,1,1,1],padding='VALID') - mu1_mu2\n",
    "    if cs_map:\n",
    "        value = (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2)),\n",
    "                (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
    "    else:\n",
    "        value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
    "                    (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if mean_metric:\n",
    "        value = tf.reduce_mean(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "class LeakyReLU(LeakyReLU):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__name__ = \"LeakyReLU\"\n",
    "        super(LeakyReLU, self).__init__(**kwargs)  \n",
    "\n",
    "\n",
    "def mean_sq_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def psnr(y_true, y_pred):\n",
    "    return tf_psnr(y_true, y_pred, max_val=1.0, name=None)\n",
    "def tf_psnr(a, b, max_val, name=None):\n",
    "    \"\"\"Returns the Peak Signal-to-Noise Ratio between a and b.\n",
    "    This is intended to be used on signals (or images). Produces a PSNR value for\n",
    "    each image in batch.\n",
    "    The last three dimensions of input are expected to be [height, width, depth].\n",
    "    Example:\n",
    "    ```python\n",
    "    # Read images from file.\n",
    "    im1 = tf.decode_png('path/to/im1.png')\n",
    "    im2 = tf.decode_png('path/to/im2.png')\n",
    "    # Compute PSNR over tf.uint8 Tensors.\n",
    "    psnr1 = tf.image.psnr(im1, im2, max_val=255)\n",
    "    # Compute PSNR over tf.float32 Tensors.\n",
    "    im1 = tf.image.convert_image_dtype(im1, tf.float32)\n",
    "    im2 = tf.image.convert_image_dtype(im2, tf.float32)\n",
    "    psnr2 = tf.image.psnr(im1, im2, max_val=1.0)\n",
    "    # psnr1 and psnr2 both have type tf.float32 and are almost equal.\n",
    "    ```\n",
    "    Arguments:\n",
    "    a: First set of images.\n",
    "    b: Second set of images.\n",
    "    max_val: The dynamic range of the images (i.e., the difference between the\n",
    "    maximum the and minimum allowed values).\n",
    "    name: Namespace to embed the computation in.\n",
    "    Returns:\n",
    "    The scalar PSNR between a and b. The returned tensor has type `tf.float32`\n",
    "    and shape [batch_size, 1].\n",
    "    \"\"\"\n",
    "    with ops.name_scope(name, 'PSNR', [a, b]):\n",
    "    # Need to convert the images to float32.  Scale max_val accordingly so that\n",
    "    # PSNR is computed correctly.\n",
    "        max_val = math_ops.cast(max_val, a.dtype)\n",
    "#         max_val = convert_image_dtype(max_val, dtypes.float32)\n",
    "#         a = convert_image_dtype(a, dtypes.float32)\n",
    "#         b = convert_image_dtype(b, dtypes.float32)\n",
    "        mse = math_ops.reduce_mean(math_ops.squared_difference(a, b), [-4, -3, -2])\n",
    "        psnr_val = math_ops.subtract(\n",
    "        20 * math_ops.log(max_val) / math_ops.log(10.0),\n",
    "        np.float64(10 / np.log(10)) * math_ops.log(mse),\n",
    "        name='psnr')\n",
    "\n",
    "#         _, _, checks = _verify_compatible_image_shapes(a, b)\n",
    "#         with ops.control_dependencies(checks):\n",
    "        return array_ops.identity(psnr_val)\n",
    "        \n",
    "def DenseNet(patch_size=64, growth_rate=24):\n",
    "    n_channels=growth_rate\n",
    "    input_shape=(patch_size, patch_size, patch_size, 1)\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "    #Initial Convolution Layer\n",
    "    x = Conv3D(filters=2*growth_rate,  kernel_size=(3, 3, 3), padding='same', activation = LeakyReLU(alpha=0.1))(inputs)\n",
    "\n",
    "    no_layers = 4\n",
    "    for i in range(no_layers):\n",
    "        x_list = [x]\n",
    "        cb = Conv3D(filters=2*growth_rate,  kernel_size=(3, 3, 3), padding='same', activation = LeakyReLU(alpha=0.1))(x)\n",
    "        x_list.append(cb)\n",
    "        x = Concatenate(axis=-1)(x_list)\n",
    "        \n",
    "        n_channels += growth_rate\n",
    "        # for transititon layer\n",
    "        x = Conv3D( n_channels,kernel_size=(1, 1, 1), padding='same', activation = LeakyReLU(alpha=0.1)) (x)\n",
    "        \n",
    "\n",
    "    x = Conv3D( 1,kernel_size=(3, 3, 3), padding='same') (x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    adamOpt = Adam(lr=0.00001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adamOpt,metrics=[mean_sq_error, psnr, ssim ])\n",
    "    model.summary(line_length=110)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerator = tf.log(tf.constant(0.0190))\n",
    "# # denom = tf.log(tf.constant(10, dtype=tf.float64))# psnr_random(10)\n",
    "# # res = numerator / denom\n",
    "# # init_op = tf.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init_op) #execute init_op\n",
    "#     #print the random values that we sample\n",
    "#     print (sess.run(numerator))\n",
    "\n",
    "# print( np.log(0.0190))\n",
    "# print( np.log(0.0190) / np.log(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________________________\n",
      "Layer (type)                        Output Shape            Param #      Connected to                         \n",
      "==============================================================================================================\n",
      "input_2 (InputLayer)                (None, 64, 64, 64, 1)   0                                                 \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)                  (None, 64, 64, 64, 48)  1344         input_2[0][0]                        \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)                  (None, 64, 64, 64, 48)  62256        conv3d_11[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)         (None, 64, 64, 64, 96)  0            conv3d_11[0][0]                      \n",
      "                                                                         conv3d_12[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)                  (None, 64, 64, 64, 48)  4656         concatenate_5[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)                  (None, 64, 64, 64, 48)  62256        conv3d_13[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)         (None, 64, 64, 64, 96)  0            conv3d_13[0][0]                      \n",
      "                                                                         conv3d_14[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)                  (None, 64, 64, 64, 72)  6984         concatenate_6[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)                  (None, 64, 64, 64, 48)  93360        conv3d_15[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)         (None, 64, 64, 64, 120) 0            conv3d_15[0][0]                      \n",
      "                                                                         conv3d_16[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)                  (None, 64, 64, 64, 96)  11616        concatenate_7[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)                  (None, 64, 64, 64, 48)  124464       conv3d_17[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)         (None, 64, 64, 64, 144) 0            conv3d_17[0][0]                      \n",
      "                                                                         conv3d_18[0][0]                      \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)                  (None, 64, 64, 64, 120) 17400        concatenate_8[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)                  (None, 64, 64, 64, 1)   3241         conv3d_19[0][0]                      \n",
      "==============================================================================================================\n",
      "Total params: 387,577\n",
      "Trainable params: 387,577\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=DenseNet(patch_size=64, growth_rate=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Loading and preprocessing train data 64x64x64 Patch Size..\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Loading and preprocessing validation data 64x64x64 Patch Size..\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "patch_size=64\n",
    "from keras.utils import plot_model\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "import time\n",
    "train_batch_size = 1\n",
    "reduceLearningRate  = 0.5\n",
    "\n",
    "\n",
    "print('-'*60)\n",
    "print('Loading and preprocessing train data 64x64x64 Patch Size..')\n",
    "print('-'*60)\n",
    "trainImg = np.load('patches3D/patchesStandardized/patchesTrainImgLR.npy')\n",
    "trainGt = np.load('patches3D/patchesStandardized/patchesTrainImgHR.npy')\n",
    "\n",
    "print('-'*60)\n",
    "print('Loading and preprocessing validation data 64x64x64 Patch Size..')\n",
    "print('-'*60)\n",
    "valImg = np.load('patches3D/patchesStandardized/patchesvalImgLR.npy')\n",
    "valGt = np.load('patches3D/patchesStandardized/patchesvalImgHR.npy')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Fitting model...\n",
      "------------------------------------------------------------\n",
      "training starting..\n",
      "Train on 2100 samples, validate on 630 samples\n",
      "Epoch 1/2\n",
      "  35/2100 [..............................] - ETA: 43:43 - loss: 0.0373 - mean_sq_error: 0.0373 - psnr: 16.3246 - ssim: 0.2439"
     ]
    }
   ],
   "source": [
    "\n",
    "print('-'*60)\n",
    "print('Fitting model...')\n",
    "print('-'*60)\n",
    "\n",
    "#============================================================================\n",
    "print('training starting..')\n",
    "\n",
    "if 'outputs' not in os.listdir(os.curdir):\n",
    "    os.mkdir('outputs')\n",
    "\n",
    "\n",
    "log_filename = 'outputs/' + '3dPatch' +'_model_train.csv'\n",
    "\n",
    "csv_log = callbacks.CSVLogger(log_filename, separator=',', append=True)\n",
    "\n",
    "checkpoint_filepath = 'outputs/' + 'model-{epoch:03d}.h5'\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [csv_log, checkpoint]\n",
    "callbacks_list.append(ReduceLROnPlateau(factor=reduceLearningRate, patience=3,\n",
    "                                           verbose=True))\n",
    "callbacks_list.append(EarlyStopping(verbose=True, patience=3))\n",
    "\n",
    "#============================================================================\n",
    "history = model.fit(trainImg, trainGt, epochs=2, verbose=1, batch_size=train_batch_size , validation_data=(valImg,valGt), shuffle=True, callbacks=callbacks_list) \n",
    "\n",
    "model_name = 'outputs/' + '3dPatch64' + '_model_last'\n",
    "model.save(model_name)  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
